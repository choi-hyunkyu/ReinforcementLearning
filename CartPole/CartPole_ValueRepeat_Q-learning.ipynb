{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning\n",
    "\n",
    "클래스를 정의해서 CartPole을 구현한다.\n",
    "\n",
    "* Agent\n",
    "    CartPole의 수레에 해당\n",
    "    update_Q_function과 get_action의 메서드를 가지고 있음\n",
    "    Brain 클래스 객체를 멤버 변수로 가짐\n",
    "\n",
    "* Brain\n",
    "    Agent 클래스의 두뇌 역할\n",
    "    Q 테이블을 이용해 Q-learning이 구현됨\n",
    "    bins, digitize_state, update_Q_table, decide_action의 메서드를 가지고 있음\n",
    "    bins, digitize_state: Agent가 관측한 생태 observation을 이산 변수로 변환\n",
    "\n",
    "* Environment\n",
    "    OpenAI Gym이 실행되는 실행 환경\n",
    "    CartPole을 실행하며 실행을 맡을 run 메서드를 가지고 있음\n",
    "\n",
    "Agent와 Brain을 별도의 클래스로 분리한 것은 딥러닝에서 Brain 클래스로 국한되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현 과정\n",
    "\n",
    "* #### Action 결정 (Agent -> Brain -> Agent)\n",
    "    * 행동을 결정하기 위해 Agent는 현재 상태 observation_t를 Brain 클래스에 전달한다.\n",
    "\n",
    "    * Brain 클래스는 전달받은 상태변수를 이산변수로 변환한 다음 Q_table을 참조해서 행동을 결정한다\n",
    "\n",
    "    * 결정된 현재 행동 action_t를 Agent에 전달한다.\n",
    "    \n",
    "* #### Action 실행 (Agent -> Environment -> Agent)\n",
    "    * Agent는 Environment에 행동 action_t를 전달하며 Action을 취한 다음 Environment를 한 단계 진행시킨다.\n",
    "\n",
    "    * Environment는 다시 행동 action_t를 실행한 결과가 되는 상태 observation_t+1과 이때 얻은 즉각보상 reward_t+1을 Agent에 반환한다.\n",
    "\n",
    "* #### Q_table 수정 (Agent -> Brain)\n",
    "    * Agent는 현재 상태 observation_t, 조금 전 취했던 행동 action_t, 행동의 결과로 얻은 새로운 상태 observation_t+1과 받게된 즉각보상 reward_t+1 네 개의 변수를 Brain에 전달한다.\n",
    "    * Brain은 전달받은 변수를 통해 기존의 Q_table을 수정한다.\n",
    "    * observation_t, action_t, observation_t+1, reward_t+1 네 개의 변수를 합쳐놓은 것을 'Transition'이라고 부른다.\n",
    "    \n",
    "\n",
    "Action 결정, Action 실행, Q_table 수정과 같이 세부과정을 포함한 총 세 개의 절차를 반복하며 Q_learning이 수행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 구조 및 정보 흐름 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "애니메이션 함수 정의\n",
    "'''\n",
    "\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \n",
    "    plt.figure(figsize = (frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "        \n",
    "    anim = animation.FuncAnimation(\n",
    "        plt.gcf(), \n",
    "        animate, \n",
    "        frames = len(frames), \n",
    "        interval = 50\n",
    "    )\n",
    "    \n",
    "    anim.save('CartPole_Q-learning.gif')\n",
    "    display(display_animation(anim, default_mode = 'loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "상수 정의\n",
    "'''\n",
    "\n",
    "# 태스크 네임\n",
    "ENV = 'CartPole-v0'\n",
    "\n",
    "# 각 상태를 이산변수로 변환할 구간 수\n",
    "num_digitized = 6\n",
    "\n",
    "# 시간할인율\n",
    "gamma = 0.99 \n",
    "\n",
    "# 학습률\n",
    "eta = 0.5\n",
    "\n",
    "# Epoch당 최대 단계 수\n",
    "# CartPole-v0은 200단계를 버티면 클리어로 간주\n",
    "max_steps = 200\n",
    "\n",
    "# 최대 Epoch\n",
    "nb_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Agent 클래스 구현\n",
    "\n",
    "생성자 메서드인 __init__()에서 상태변수의 수와 행동의 가짓수를 전달받고, 두뇌 역할을 할 Brain 클래스의 인스턴스를 만든다.\n",
    "'''\n",
    "\n",
    "# 실제 Agent의 역할을 하는 클래스\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, num_states, num_actions):\n",
    "        \n",
    "        # Agent의 행동을 결정하는 두뇌 역할 (Brain class 참조)\n",
    "        self.brain = Brain(num_states, num_actions)\n",
    "        \n",
    "    def update_Q_function(self, observation, action, reward, observation_next):\n",
    "        \n",
    "        # Brain에 전달 및 Q_table 수정 (Brain class 참조)\n",
    "        self.brain.update_Q_table(observation, action, reward, observation_next)\n",
    "        \n",
    "    def get_action(self, observation, step):\n",
    "        \n",
    "        # 행동 결정 (Brain class 참조)\n",
    "        action = self.brain.decide_action(observation, step)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Brain 클래스 구현\n",
    "\n",
    "Q_table을 수정하는 방법과 다음 행동을 결정하는 방법은 epsilon-greedy 알고리즘을 이용하여 구현한다.\n",
    "'''\n",
    "\n",
    "# Agent의 두뇌 역할을 하는 클래스\n",
    "class Brain:\n",
    "    \n",
    "    def __init__(self, num_states, num_actions):\n",
    "        \n",
    "        # 행동의 가짓수(왼쪽, 오른쪽)를 구함\n",
    "        self.num_actions = num_actions\n",
    "    \n",
    "        # Q_table 생성\n",
    "        self.Q_table = np.random.uniform(\n",
    "        \n",
    "                low = 0, \n",
    "                high = 1,\n",
    "                size = (\n",
    "            \n",
    "                    # 행 수는 상태를 구간수**4(변수의 수 = 4)가지 값 중 하나로 변환한 값\n",
    "                    num_digitized ** num_states,\n",
    "            \n",
    "                    # 열 수는 행동의 가지수\n",
    "                    num_actions\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # 관측된 상태(연속값)을 이산변수로 변환하는 구간 계산\n",
    "    def bins(self, clip_min, clip_max, num):\n",
    "        \n",
    "        return np.linspace(clip_min, clip_max, num + 1)[1: -1]\n",
    "    \n",
    "    # 관측된 상태 observation을 이산변수로 변환\n",
    "    def digitize_state(self, observation):\n",
    "        \n",
    "        cart_pos, cart_v, pole_angle, pole_v = observation\n",
    "        digitized = [\n",
    "            np.digitize(cart_pos, bins = self.bins(-2.4, 2.4, num_digitized)),\n",
    "            np.digitize(cart_v, bins = self.bins(-3.0, 3.0, num_digitized)),\n",
    "            np.digitize(pole_angle, bins = self.bins(-0.5, 0.5, num_digitized)),\n",
    "            np.digitize(pole_v, bins = self.bins(-2.0, 2.0, num_digitized))\n",
    "        ]\n",
    "        \n",
    "        return sum([x * (num_digitized ** i) for i, x in enumerate(digitized)])\n",
    "    \n",
    "    # Q-learning으로 Q_table 수정\n",
    "    def update_Q_table(self, observation, action, reward, observation_next):\n",
    "        \n",
    "        # 상태를 이산변수로 변환\n",
    "        state = self.digitize_state(observation)\n",
    "        \n",
    "        # 다음 상태를 이산변수로 변환\n",
    "        state_next = self.digitize_state(observation_next)\n",
    "        \n",
    "        Max_Q_next = max(self.Q_table[state_next][:])\n",
    "        self.Q_table[state, action] = self.Q_table[state, action] + eta * (reward + gamma * Max_Q_next - self.Q_table[state, action])\n",
    "    \n",
    "    # epsilon-greedy 알고리즘을 적용하여 서서히 최적행동의 비중을 증가시킴\n",
    "    def decide_action(self, observation, epoch):\n",
    "        \n",
    "        state = self.digitize_state(observation)\n",
    "        epsilon = 0.5 * (1 / (epoch + 1))\n",
    "        \n",
    "        # 두 가지 행동 중 하나를 무작위 선택\n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            action = np.argmax(self.Q_table[state][:])\n",
    "        \n",
    "        else:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Environment 클래스 구현\n",
    "'''\n",
    "\n",
    "# OpenAI Gym이 실행되는 실행 환경 CartPole을 실행\n",
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # 실행할 태스크 설정\n",
    "        self.env = gym.make(ENV)\n",
    "        \n",
    "        # 태스크의 상태 변수 수를 구함\n",
    "        num_states = self.env.observation_space.shape[0]\n",
    "        \n",
    "        # 가능한 행동 수를 구함\n",
    "        num_actions = self.env.action_space.n\n",
    "        \n",
    "        # Agent 객체 생성\n",
    "        self.agent = Agent(num_states, num_actions)\n",
    "    \n",
    "    # 실행\n",
    "    def run(self):\n",
    "        \n",
    "        # 195단계 이상 버틴 epoch 수\n",
    "        complete_epochs = 0\n",
    "        \n",
    "        # 마지막 epoch 여부\n",
    "        is_epoch_final = False\n",
    "        \n",
    "        # 애니메이션을 만드는 데 사용할 이미지를 저장하는 변수\n",
    "        frames = []\n",
    "        \n",
    "        # nb_epoch 만큼 반복\n",
    "        for epoch in range(nb_epochs):\n",
    "            \n",
    "            # 환경 초기화\n",
    "            observation = self.env.reset()\n",
    "            \n",
    "            # 각 epoch에 해당하는 반복\n",
    "            for step in range(max_steps):\n",
    "                \n",
    "                # 마지막 에피소드면 frames에 각 단계의 이미지를 저장\n",
    "                if is_epoch_final is True:\n",
    "                    frames.append(self.env.render(mode = 'rgb_array'))\n",
    "                    \n",
    "                # 행동 선택\n",
    "                action = self.agent.get_action(observation, epoch)\n",
    "                \n",
    "                # 행동 action_t를 실행해 state_t+1, reward_t+1을 계산\n",
    "                # reward, info는 사용하지 않으므로 under-bar로 처리\n",
    "                observation_next, _, done, _ = self.env.step(action)\n",
    "                \n",
    "                # 보상 부여\n",
    "                if done:\n",
    "                    \n",
    "                    # 200단계를 넘어서거나 일정 각도 이상 기울면 done의 값이 True가 됨\n",
    "                    if step < 195:\n",
    "                        \n",
    "                        # 봉이 쓰러지면 패널티 보상 -1 부여\n",
    "                        reward = -1\n",
    "                        \n",
    "                        # 195단계 이상 버티면 해당 epoch 성공 처리\n",
    "                        complete_epochs = 0\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        # 쓰러지지 않고 epoch를 끝내면 보상 1 부여\n",
    "                        reward = 1\n",
    "                        \n",
    "                        # epoch 연속 성공 기록을 업데이트\n",
    "                        complete_epochs += 1\n",
    "                        \n",
    "                # epoch 중에는 보상 0 부여\n",
    "                else:\n",
    "                    reward = 0\n",
    "                    \n",
    "                # 다음 단계 상태 observation_next로 Q함수 수정\n",
    "                self.agent.update_Q_function(observation, action, reward, observation_next)\n",
    "                \n",
    "                # 다음 단계 상태 업데이트\n",
    "                observation = observation_next\n",
    "                \n",
    "                # epoch 마무리\n",
    "                if done:\n",
    "                    print(\"{} Epoch was finished after {} time steps\".format(epoch, step + 1))\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "            # 마지막 epoch에서 애니메이션을 만들고 저장\n",
    "            if is_epoch_final is True:\n",
    "                display_frames_as_gif(frames)\n",
    "                \n",
    "                break\n",
    "                \n",
    "            # 10연속 이상 성공한 경우(195단계 이상 지속) 조기 종료\n",
    "            if complete_epochs >= 10:\n",
    "                print('10연속 이상 성공했습니다.')\n",
    "                is_epoch_final = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Epoch was finished after 17 time steps\n",
      "1 Epoch was finished after 13 time steps\n",
      "2 Epoch was finished after 33 time steps\n",
      "3 Epoch was finished after 23 time steps\n",
      "4 Epoch was finished after 32 time steps\n",
      "5 Epoch was finished after 29 time steps\n",
      "6 Epoch was finished after 181 time steps\n",
      "7 Epoch was finished after 31 time steps\n",
      "8 Epoch was finished after 45 time steps\n",
      "9 Epoch was finished after 160 time steps\n",
      "10 Epoch was finished after 23 time steps\n",
      "11 Epoch was finished after 25 time steps\n",
      "12 Epoch was finished after 25 time steps\n",
      "13 Epoch was finished after 16 time steps\n",
      "14 Epoch was finished after 12 time steps\n",
      "15 Epoch was finished after 26 time steps\n",
      "16 Epoch was finished after 21 time steps\n",
      "17 Epoch was finished after 52 time steps\n",
      "18 Epoch was finished after 32 time steps\n",
      "19 Epoch was finished after 27 time steps\n",
      "20 Epoch was finished after 183 time steps\n",
      "21 Epoch was finished after 59 time steps\n",
      "22 Epoch was finished after 83 time steps\n",
      "23 Epoch was finished after 24 time steps\n",
      "24 Epoch was finished after 12 time steps\n",
      "25 Epoch was finished after 32 time steps\n",
      "26 Epoch was finished after 28 time steps\n",
      "27 Epoch was finished after 30 time steps\n",
      "28 Epoch was finished after 12 time steps\n",
      "29 Epoch was finished after 20 time steps\n",
      "30 Epoch was finished after 13 time steps\n",
      "31 Epoch was finished after 47 time steps\n",
      "32 Epoch was finished after 39 time steps\n",
      "33 Epoch was finished after 10 time steps\n",
      "34 Epoch was finished after 29 time steps\n",
      "35 Epoch was finished after 65 time steps\n",
      "36 Epoch was finished after 99 time steps\n",
      "37 Epoch was finished after 34 time steps\n",
      "38 Epoch was finished after 67 time steps\n",
      "39 Epoch was finished after 23 time steps\n",
      "40 Epoch was finished after 73 time steps\n",
      "41 Epoch was finished after 11 time steps\n",
      "42 Epoch was finished after 11 time steps\n",
      "43 Epoch was finished after 100 time steps\n",
      "44 Epoch was finished after 83 time steps\n",
      "45 Epoch was finished after 66 time steps\n",
      "46 Epoch was finished after 54 time steps\n",
      "47 Epoch was finished after 11 time steps\n",
      "48 Epoch was finished after 12 time steps\n",
      "49 Epoch was finished after 18 time steps\n",
      "50 Epoch was finished after 9 time steps\n",
      "51 Epoch was finished after 25 time steps\n",
      "52 Epoch was finished after 126 time steps\n",
      "53 Epoch was finished after 32 time steps\n",
      "54 Epoch was finished after 46 time steps\n",
      "55 Epoch was finished after 114 time steps\n",
      "56 Epoch was finished after 63 time steps\n",
      "57 Epoch was finished after 18 time steps\n",
      "58 Epoch was finished after 52 time steps\n",
      "59 Epoch was finished after 106 time steps\n",
      "60 Epoch was finished after 112 time steps\n",
      "61 Epoch was finished after 39 time steps\n",
      "62 Epoch was finished after 72 time steps\n",
      "63 Epoch was finished after 24 time steps\n",
      "64 Epoch was finished after 49 time steps\n",
      "65 Epoch was finished after 47 time steps\n",
      "66 Epoch was finished after 169 time steps\n",
      "67 Epoch was finished after 153 time steps\n",
      "68 Epoch was finished after 172 time steps\n",
      "69 Epoch was finished after 103 time steps\n",
      "70 Epoch was finished after 133 time steps\n",
      "71 Epoch was finished after 97 time steps\n",
      "72 Epoch was finished after 36 time steps\n",
      "73 Epoch was finished after 72 time steps\n",
      "74 Epoch was finished after 82 time steps\n",
      "75 Epoch was finished after 18 time steps\n",
      "76 Epoch was finished after 16 time steps\n",
      "77 Epoch was finished after 83 time steps\n",
      "78 Epoch was finished after 45 time steps\n",
      "79 Epoch was finished after 102 time steps\n",
      "80 Epoch was finished after 67 time steps\n",
      "81 Epoch was finished after 105 time steps\n",
      "82 Epoch was finished after 200 time steps\n",
      "83 Epoch was finished after 61 time steps\n",
      "84 Epoch was finished after 200 time steps\n",
      "85 Epoch was finished after 68 time steps\n",
      "86 Epoch was finished after 18 time steps\n",
      "87 Epoch was finished after 19 time steps\n",
      "88 Epoch was finished after 200 time steps\n",
      "89 Epoch was finished after 200 time steps\n",
      "90 Epoch was finished after 200 time steps\n",
      "91 Epoch was finished after 76 time steps\n",
      "92 Epoch was finished after 200 time steps\n",
      "93 Epoch was finished after 200 time steps\n",
      "94 Epoch was finished after 48 time steps\n",
      "95 Epoch was finished after 61 time steps\n",
      "96 Epoch was finished after 30 time steps\n",
      "97 Epoch was finished after 34 time steps\n",
      "98 Epoch was finished after 200 time steps\n",
      "99 Epoch was finished after 24 time steps\n",
      "100 Epoch was finished after 31 time steps\n",
      "101 Epoch was finished after 200 time steps\n",
      "102 Epoch was finished after 200 time steps\n",
      "103 Epoch was finished after 200 time steps\n",
      "104 Epoch was finished after 200 time steps\n",
      "105 Epoch was finished after 200 time steps\n",
      "106 Epoch was finished after 151 time steps\n",
      "107 Epoch was finished after 200 time steps\n",
      "108 Epoch was finished after 200 time steps\n",
      "109 Epoch was finished after 200 time steps\n",
      "110 Epoch was finished after 97 time steps\n",
      "111 Epoch was finished after 200 time steps\n",
      "112 Epoch was finished after 200 time steps\n",
      "113 Epoch was finished after 200 time steps\n",
      "114 Epoch was finished after 132 time steps\n",
      "115 Epoch was finished after 77 time steps\n",
      "116 Epoch was finished after 45 time steps\n",
      "117 Epoch was finished after 114 time steps\n",
      "118 Epoch was finished after 200 time steps\n",
      "119 Epoch was finished after 200 time steps\n",
      "120 Epoch was finished after 200 time steps\n",
      "121 Epoch was finished after 152 time steps\n",
      "122 Epoch was finished after 109 time steps\n",
      "123 Epoch was finished after 156 time steps\n",
      "124 Epoch was finished after 200 time steps\n",
      "125 Epoch was finished after 200 time steps\n",
      "126 Epoch was finished after 200 time steps\n",
      "127 Epoch was finished after 200 time steps\n",
      "128 Epoch was finished after 97 time steps\n",
      "129 Epoch was finished after 200 time steps\n",
      "130 Epoch was finished after 96 time steps\n",
      "131 Epoch was finished after 200 time steps\n",
      "132 Epoch was finished after 200 time steps\n",
      "133 Epoch was finished after 90 time steps\n",
      "134 Epoch was finished after 200 time steps\n",
      "135 Epoch was finished after 200 time steps\n",
      "136 Epoch was finished after 200 time steps\n",
      "137 Epoch was finished after 200 time steps\n",
      "138 Epoch was finished after 200 time steps\n",
      "139 Epoch was finished after 200 time steps\n",
      "140 Epoch was finished after 200 time steps\n",
      "141 Epoch was finished after 200 time steps\n",
      "142 Epoch was finished after 200 time steps\n",
      "143 Epoch was finished after 200 time steps\n",
      "10연속 이상 성공했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 Epoch was finished after 10 time steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\JSAnimation\\html_writer.py:281: MatplotlibDeprecationWarning: \n",
      "The 'clear_temp' parameter of setup() was deprecated in Matplotlib 3.3 and will be removed two minor releases later. If any parameter follows 'clear_temp', they should be passed as keyword, not positionally.\n",
      "  super(HTMLWriter, self).setup(fig, outfile, dpi,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HTMLWriter' object has no attribute '_temp_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-135fd70ab5ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# main\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcartpole_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcartpole_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-2ce63a46315b>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# 마지막 epoch에서 애니메이션을 만들고 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_epoch_final\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0mdisplay_frames_as_gif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-27aa6e308ac2>\u001b[0m in \u001b[0;36mdisplay_frames_as_gif\u001b[1;34m(frames)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0manim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CartPole_Q-learning.gif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'loop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[1;34m(anim, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[1;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m#with tempfile.NamedTemporaryFile(suffix='.html') as f:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_NameOnlyTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.html'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[0m\u001b[0;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                                                  default_mode=default_mode))\n",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1135\u001b[0m                         \u001b[0mprogress_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m                         \u001b[0mframe_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m                 \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msaving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;31m# Call run here now that all frame grabbing is done. All temp files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[1;31m# are available to be assembled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[0mMovieWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Will call clean-up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choih\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\JSAnimation\\html_writer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJS_INCLUDE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             of.write(DISPLAY_TEMPLATE.format(id=self.new_id(),\n\u001b[1;32m--> 323\u001b[1;33m                                              \u001b[0mNframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m                                              \u001b[0mfill_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                                              \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HTMLWriter' object has no attribute '_temp_names'"
     ]
    }
   ],
   "source": [
    "# main\n",
    "cartpole_env = Environment()\n",
    "cartpole_env.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
