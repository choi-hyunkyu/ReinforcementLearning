{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "초기 상태 미로 크기\n",
    "'''\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "ax = plt.gca()\n",
    "\n",
    "'''\n",
    "붉은 벽 그리기\n",
    "'''\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "'''\n",
    "상태 문자열 표시: S0 ~ S8\n",
    "'''\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "'''\n",
    "범위 및 눈금 제거\n",
    "'''\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='both', \n",
    "    which='both', \n",
    "    bottom=False, \n",
    "    top=False, \n",
    "    labelbottom=False, \n",
    "    right=False, \n",
    "    left=False, \n",
    "    labelleft=False\n",
    ")\n",
    "\n",
    "'''\n",
    "Start 위치에 녹색 원으로 현재 위치 표시\n",
    "'''\n",
    "line, = ax.plot([0.5], [2.5], marker = \"o\", color = 'g', markersize = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정책 반복\n",
    "\n",
    "정책 파라미터 theta에서 pi(s,a)를 구하는 방법 중에서 softmax function을 사용한다.\n",
    "\n",
    "* softmax function을 사용하는 이유는 파라미터 theta가 음수가 돼도 계산할 수 있기 때문이다. \n",
    "* theta를 pi로 변환하는 데 softmax function을 사용하면 theta가 음수여도 확률을 계산할 수 있다는 이점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "정책 - policy - pi\n",
    "policy의 초기값 설정\n",
    "\n",
    "행은 상태 0 ~ 7, 열은 행동 방향(상, 우, 하, 좌)를 나타낸다.\n",
    "'''\n",
    "theta_0 = np.array(\n",
    "    [\n",
    "        [np.nan, 1, 1, np.nan],  # s0\n",
    "        [np.nan, 1, np.nan, 1],  # s1\n",
    "        [np.nan, np.nan, 1, 1],  # s2\n",
    "        [1, 1, 1, np.nan],  # s3\n",
    "        [np.nan, np.nan, 1, 1],  # s4\n",
    "        [1, np.nan, np.nan, np.nan],  # s5\n",
    "        [1, np.nan, np.nan, np.nan],  # s6\n",
    "        [1, 1, np.nan, np.nan],  # s7\n",
    "        # ※s8은 목표지점이므로 정책이 없다\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan  1.  1. nan]\n",
      " [nan  1. nan  1.]\n",
      " [nan nan  1.  1.]\n",
      " [ 1.  1.  1. nan]\n",
      " [nan nan  1.  1.]\n",
      " [ 1. nan nan nan]\n",
      " [ 1. nan nan nan]\n",
      " [ 1.  1. nan nan]]\n",
      "(8, 4)\n"
     ]
    }
   ],
   "source": [
    "print(theta_0)\n",
    "print(theta_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_convert_into_pi_from_theta(theta):\n",
    "    \n",
    "    # inverse temperature\n",
    "    beta = 1.0\n",
    "    \n",
    "    # theta 행렬의 크기\n",
    "    [m, n] = theta.shape\n",
    "    \n",
    "    pi = np.zeros((m, n))\n",
    "    \n",
    "    # theta를 exp(theta)로 치환\n",
    "    exp_theta = np.exp(beta * theta)\n",
    "    \n",
    "    for i in range(0, m):\n",
    "        \n",
    "        # softmax function을 이용한 비율 계산\n",
    "        pi[i, :] = exp_theta[i, :] / np.nansum(exp_theta[i, :])\n",
    "    \n",
    "    # nan을 0으로 치환\n",
    "    pi = np.nan_to_num(pi)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정의된 함수를 실행하여 theta zero로부터 초기 policy pi(s,a)를 구한다.\n",
    "'''\n",
    "pi_0 = softmax_convert_into_pi_from_theta(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.5        0.5        0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.5        0.5        0.         0.        ]]\n",
      "(8, 4)\n"
     ]
    }
   ],
   "source": [
    "print(pi_0)\n",
    "print(pi_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "에이전트가 policy - pi(s,a)를 따라 행동하게 만든다.\n",
    "1단계 이동 후 에이전트의 상태를 구하는 함수를 정의한다.\n",
    "'''\n",
    "def get_action_and_next_state(pi, state):\n",
    "    \n",
    "    # 상, 우, 하, 좌\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    \n",
    "    # pi[s, :]의 확률에 따라서 direction 값이 선택\n",
    "    next_direction = np.random.choice(direction, p = pi[state, :])\n",
    "    \n",
    "    if next_direction == \"up\":\n",
    "        \n",
    "        action = 0\n",
    "        \n",
    "        # 위쪽으로 이동하면 상태값이 3만큼 감소\n",
    "        s_next = state - 3\n",
    "        \n",
    "    elif next_direction == \"right\":\n",
    "        \n",
    "        action = 1\n",
    "        \n",
    "        # 오른쪽으로 이동하면 상태값이 1만큼 증가\n",
    "        s_next = state + 1\n",
    "        \n",
    "    elif next_direction == \"down\":\n",
    "        \n",
    "        action = 2\n",
    "        \n",
    "        # 아래쪽으로 이동하면 상태값이 3만큼 증가\n",
    "        s_next = state + 3\n",
    "        \n",
    "    elif next_direction == \"left\":\n",
    "        \n",
    "        action = 3\n",
    "        \n",
    "        # 왼쪽으로 이동하면 상태값이 1만큼 감소\n",
    "        s_next = state - 1\n",
    "        \n",
    "    return [action, s_next]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "에이전트가 목표에 도달할 때까지 pi(s,a)에 따라 get_action_and_next_s 함수로 에이전트를 이동하며 계속 진행한다.\n",
    "목표 지점에 도달할 때까지 에이전트를 계속 이동시키는 함수를 정의하고 while 문을 반복수행하며 상태와 행동 이력을 저장한다.\n",
    "마지막에 상태와 행동을 반환한다.\n",
    "'''\n",
    "def goal_maze_ret_state_action(pi):\n",
    "    \n",
    "    # 시작 지점\n",
    "    state = 0\n",
    "    \n",
    "    # 에이전트의 행동과 상태를 기록하는 리스트\n",
    "    state_action_history = [[0, np.nan]]\n",
    "    \n",
    "    # 목표 지점에 이를 때까지 반복\n",
    "    while(1):\n",
    "        [action, next_s] = get_action_and_next_state(pi, state)\n",
    "        \n",
    "        # 현재 상태(마지막이므로 인덱스가 -1)를 state_action_history에 추가\n",
    "        state_action_history[-1][1] = action\n",
    "        \n",
    "        # 경로 리스트에 다음 상태를 추가, 행동은 아직 알 수 없으므로 nan으로 추가\n",
    "        state_action_history.append([next_s, np.nan])\n",
    "        \n",
    "        # 목표 지점에 도달하면 종료\n",
    "        if next_s == 8:\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            state = next_s\n",
    "            \n",
    "    return state_action_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "goal_maze_ret_state_action 함수를 사용하여 policy - pi(s,a)를 따라 에이전트를 이동시키고, 상태 이력을 state_history에 저장한다.\n",
    "'''\n",
    "state_action_history = goal_maze_ret_state_action(pi_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2], [3, 1], [4, 2], [7, 1], [8, nan]]\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n"
     ]
    }
   ],
   "source": [
    "print(state_action_history)\n",
    "print(\"목표 지점(S8)에 도달하기까지 걸린 단계 수:\", len(state_action_history) - 1, \"단계\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정책경사 알고리즘으로 정책 수정\n",
    "\n",
    "#### theta = theta + eta * delta_theta\n",
    "#### delta_theta = {N(s(i), a(j)) + Pi(s(i), a(j)) * N(s(i), a(j))} / T\n",
    "#### theta = theta + eta * {N(s(i), a(j)) + Pi(s(i), a(j)) * N(s(i), a)} / T\n",
    "\n",
    "* theta는 상태 s(i)에서 행동 a(j)를 취할 확률을 결정하는 파라미터다. \n",
    "* eta는 학습률이라고 하며, theta가 1번 학습에 수정되는 정도를 제어한다. eta 값이 너무 작으면 학습 속도가 너무 늦어지고, 반대로 너무 크면 학습이 잘 안된다.\n",
    "\n",
    "* N(s(i), a(j))는 상태 s(i)에서 행동 a(j)을 취한 횟수의 합계이다.\n",
    "* Pi(s(i), a(j))는 현재 정책하에서 상태 s(i)일 때 행동 a(j)를 취할 확률을 나타낸다.\n",
    "* N(s(i), a)는 상태 s(i)에서 모든 행동을 취한 횟수의 합계이다.\n",
    "* T는 목표 지점에 이르기까지 걸린 모든 단계의 수다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "theta를 수정하는 함수 정의\n",
    "'''\n",
    "\n",
    "def update_theta(theta, pi, state_action_history):\n",
    "    \n",
    "    # learning rate\n",
    "    eta = 0.1\n",
    "    \n",
    "    # 목표 지점에 도달하기 까지 걸린 단계 수\n",
    "    T = len(state_action_history) - 1\n",
    "    \n",
    "    # theta 행렬의 크기\n",
    "    [m, n] = theta.shape\n",
    "    \n",
    "    # delta theta를 구할 준비, 포인터 참조이므로 delta_theta = theta로는 안됨\n",
    "    delta_theta = theta.copy()\n",
    "    \n",
    "    # delta_theta 요소 단위 계산\n",
    "    for i in range(0, m):\n",
    "        for j in range(0, n):\n",
    "            \n",
    "            # theta가 nan이 아닌 경우\n",
    "            if not(np.isnan(theta[i, j])):\n",
    "                \n",
    "                # 히스토리에서 상태 i인 것만 모아오는 리스트 컴프리헨션\n",
    "                state_action_i = [state_action for state_action in state_action_history if state_action[0] == i]\n",
    "                \n",
    "                # 상태 i에서 행동 j를 취한 경우만 모음\n",
    "                state_action_ij = [state_action for state_action in state_action_history if state_action == [i, j]]\n",
    "                \n",
    "                # 상태 i에서 모든 행동을 취한 횟수\n",
    "                N_i = len(state_action_i)\n",
    "                \n",
    "                # 상태 i에서 행동 j를 취한 횟수\n",
    "                N_ij = len(state_action_ij)\n",
    "                \n",
    "                delta_theta[i, j] = (N_ij + pi[i, j] * N_i) / T\n",
    "                \n",
    "    updated_theta = theta + eta * delta_theta\n",
    "    \n",
    "    return updated_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "policy 수정\n",
    "'''\n",
    "updated_theta = update_theta(theta_0, pi_0, state_action_history)\n",
    "updated_pi = softmax_convert_into_pi_from_theta(updated_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.49375033 0.50624967 0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [0.33054408 0.33891184 0.33054408 0.        ]\n",
      " [0.         0.         0.50624967 0.49375033]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.49375033 0.50624967 0.         0.        ]]\n",
      "(8, 4)\n"
     ]
    }
   ],
   "source": [
    "print(updated_pi)\n",
    "print(updated_pi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0075818125441380335\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 74 단계\n",
      "0.01801995709924631\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 16 단계\n",
      "0.010727701634101583\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 108 단계\n",
      "0.012406062832448828\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 58 단계\n",
      "0.02433311895759932\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.048932658218371505\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.011208410062785112\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 44 단계\n",
      "0.006219228651207165\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 126 단계\n",
      "0.04956760894151624\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.013353997603711254\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 40 단계\n",
      "0.014389447541433842\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 26 단계\n",
      "0.014582883138744951\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.004197327590744704\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 154 단계\n",
      "0.016524217885648174\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 12 단계\n",
      "0.012971412033388585\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.010508216260892711\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 60 단계\n",
      "0.009689929378552953\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 48 단계\n",
      "0.009530088642775825\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 28 단계\n",
      "0.02127476890355201\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.04215267718691046\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.032563558738824494\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.00906759153070441\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 70 단계\n",
      "0.0065795725079129674\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 42 단계\n",
      "0.015858172260607095\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 66 단계\n",
      "0.023094360277278847\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.011896824090308511\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 38 단계\n",
      "0.03117834936268654\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.05190360250049647\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03453356795107826\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.015441477569195394\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 42 단계\n",
      "0.028857388639549564\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.034838087074868074\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.010172503676118716\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 106 단계\n",
      "0.05338265295383976\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.023522347443936054\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 16 단계\n",
      "0.02062073430549216\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 24 단계\n",
      "0.01334004081515977\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 28 단계\n",
      "0.013975477813974957\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 26 단계\n",
      "0.023865963441421334\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.03813625263443393\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.01893052033486753\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 20 단계\n",
      "0.05468145406533104\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.007053931754890885\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 36 단계\n",
      "0.055209267659046435\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.022895510097545924\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 20 단계\n",
      "0.02410034496091723\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 24 단계\n",
      "0.009288175439037039\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 66 단계\n",
      "0.017662430357674452\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.01245600667243335\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 86 단계\n",
      "0.016433585117803406\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 36 단계\n",
      "0.012316832419935142\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 46 단계\n",
      "0.02631184682858506\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.044305224646872254\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.05634730055115106\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.011275085970317955\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 64 단계\n",
      "0.012309175616390111\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 72 단계\n",
      "0.056758810028399775\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.023363195042854\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 26 단계\n",
      "0.01857102558118523\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 34 단계\n",
      "0.015310807044112584\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 28 단계\n",
      "0.017446940815981415\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 32 단계\n",
      "0.017649413148000448\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 30 단계\n",
      "0.03698753486921502\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.013216006640041633\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 30 단계\n",
      "0.057625388962435464\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.02186306387785797\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.012832816812292425\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 28 단계\n",
      "0.020863458657392586\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.01739233066362572\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 48 단계\n",
      "0.015529113365907732\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 32 단계\n",
      "0.019692960378346502\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.021730410074523365\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 34 단계\n",
      "0.02558265380323721\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.03793201949085662\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.02679105887866079\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 20 단계\n",
      "0.028703877067528916\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.024358792539860785\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.0584158001072817\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03391003194055009\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 12 단계\n",
      "0.03734399083093948\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.03732037368014168\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.05882586234684195\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.016210811500237954\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 58 단계\n",
      "0.02430741136209988\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 16 단계\n",
      "0.05881364028713598\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.01949238452738508\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.04346209204488735\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.04336574916524977\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.027340883220116602\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 16 단계\n",
      "0.03347547645953672\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.03918721517802071\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.05813511924385817\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0450842236937983\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.020384775929829457\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 24 단계\n",
      "0.057744239993976654\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.029879943952946464\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.013614970323388736\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 32 단계\n",
      "0.057156919022950836\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.01896449733001304\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 18 단계\n",
      "0.04225894663291102\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.034370218068432795\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.05608464021682838\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03383559603422295\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 12 단계\n",
      "0.03369403663702597\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.026128475694091602\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 16 단계\n",
      "0.035856216933038476\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.03393255383162447\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.04037666158661468\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.021593102740118802\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.0535601231089006\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03192682702975161\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.0415027389999765\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.013827414312579056\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 38 단계\n",
      "0.0226245012286031\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.03578861332508998\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.025678337860711192\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.03360822434847635\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.03333689137823896\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.027697229281206465\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.03277183565225518\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.020561638777305435\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 14 단계\n",
      "0.027364659795488105\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.04832874205014917\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.021179217771946535\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 10 단계\n",
      "0.04717096871089617\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.046381441973181045\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.04557285570941237\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.034135868611283426\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.04414505685214261\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.02228577725436741\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.04284969909621751\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.04197484987920207\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.02336449059857207\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.040540079810365545\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.039642402445681554\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.026544826960556864\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.026507318362216717\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.02784077074436235\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 20 단계\n",
      "0.03737140972010157\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03645791039336323\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.028328632712413877\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.025831541605277467\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.023642589845080456\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.03344096817998424\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03253440909682201\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.028388736810384334\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.030911990105558854\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.03001271781965932\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.029121010919406033\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.028238028430618747\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.027364867445512614\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.02650256037278132\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.025652072686522337\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.02481430118102102\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.023990072731203592\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.02318014355168062\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.022385198940911146\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.021605853491228035\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.020842651740332455\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.020096069235526225\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.01936651397838954\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.013883071543627008\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.018127165332684433\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.01744710851896831\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.01678494420547423\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.016140793837929955\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.015514725202725649\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.010795266275789368\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.014482143527275514\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.011280503689403174\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.013448709024159641\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.012904234896772254\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.012377371103358598\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.011867913042948434\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.011375625909086933\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.010900247712690967\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.010441492212867368\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.009999051741695207\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.009572599911478897\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00916179419537776\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.008766278374514347\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.01176682102157947\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 8 단계\n",
      "0.008200990036374494\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.007842064994323286\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.007497107607175226\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0071657265494478135\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.006847527745980954\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.006542115906083509\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.006249095924539483\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.005968074154052952\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.005698659554286523\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.004430060505699502\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 6 단계\n",
      "0.005238749747438781\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.004999950158132392\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.004771303196508486\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.004552443352415213\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.004343012219428101\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.004142658965648036\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.003951040728422625\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0037678229389291164\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.003592679582334592\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.003425293399031219\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0032653560322066\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0031125681267362582\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0029666393841378\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.002827288578028466\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.002694243534279793\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0025672410797658186\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.002446026963349173\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0023303557524828058\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0022199907085388134\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0021147036437601198\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0020142747624546566\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.001918492488872576\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0018271532839542449\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0017400614529725555\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.001657028945874888\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.001577875151976388\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0015024266904763279\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0014305171981262243\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0013619871152295503\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0012966834710282412\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0012344596693978863\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0011751752756810892\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0011186958053696326\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0010648925152549789\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0010136421975951507\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0009648269777476844\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0009183341156678822\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0008740558115910922\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0008318890161734436\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0007917352453086561\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0007535003997856542\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0007170945899276603\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0006824319652944379\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0006494305495147808\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0006180120802815493\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.000588101854506469\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0005596285786312695\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0005325242240435903\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0005067238875634008\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00048216565690872897\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00045879048108794356\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0004365420456044388\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0004153666523894776\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00039521310435133167\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0003760325944283133\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00035777859902970497\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0003404067757473492\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0003238748652077102\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00030814259694784697\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0002931715991835236\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0002789253123501651\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00026536890628145053\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00025246920091320904\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00024019459037979756\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00022851497038050008\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00021740166871030223\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0002068273788128921\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0001967660962668895\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00018719305807239953\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0001780846846394879\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00016941852436689773\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00016117320070597167\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.0001533283616158363\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00014586463129919564\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00013876356413763743\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00013200760072551947\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00012558002591199507\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00011946492878075351\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00011364716445894545\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00010811231770178176\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "0.00010284666816132425\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n",
      "9.783715726365333e-05\n",
      "목표 지점(S8)에 도달하기까지 걸린 단계 수: 4 단계\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "미로에서 목표 지점으로 바로 갈 수 있을 만큼 파라미터 theta를 반복해서 수정하도록 하는 가장 바깥쪽 반복문을 구현한다.\n",
    "'''\n",
    "\n",
    "# policy의 변화가 10**(-4)보다 작아지면 학습 종료\n",
    "stop_epsilon = 10 ** (-4)\n",
    "\n",
    "theta = theta_0\n",
    "pi = pi_0\n",
    "is_continue = True\n",
    "count = 1\n",
    "\n",
    "# is_continue가 False가 될 때까지 반복\n",
    "while is_continue:\n",
    "    \n",
    "    # pi를 따라 미로를 탐색한 기록을 구함\n",
    "    state_action_history = goal_maze_ret_state_action(pi)\n",
    "    \n",
    "    # theta를 수정\n",
    "    updated_theta = update_theta(theta, pi, state_action_history)\n",
    "    \n",
    "    # pi를 수정\n",
    "    updated_pi = softmax_convert_into_pi_from_theta(updated_theta)\n",
    "    \n",
    "    # policy의 변화를 출력\n",
    "    delta_pi = updated_pi - pi\n",
    "    total_change_pi = np.sum(np.abs(delta_pi))\n",
    "    print(total_change_pi)\n",
    "    \n",
    "    print(\"목표 지점(S8)에 도달하기까지 걸린 단계 수:\", len(state_action_history) - 1, \"단계\")\n",
    "    \n",
    "    if total_change_pi < stop_epsilon:\n",
    "        is_continue = False\n",
    "    \n",
    "    else:\n",
    "        theta = updated_theta\n",
    "        pi = updated_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습이 끝난 policy 확인\n",
    "'''\n",
    "\n",
    "# 유효자리수: 3, 지수표시제거\n",
    "np.set_printoptions(precision = 3, suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    1.    0.   ]\n",
      " [0.    0.465 0.    0.535]\n",
      " [0.    0.    0.459 0.541]\n",
      " [0.    1.    0.    0.   ]\n",
      " [0.    0.    1.    0.   ]\n",
      " [1.    0.    0.    0.   ]\n",
      " [1.    0.    0.    0.   ]\n",
      " [0.    1.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "상태 이력을 따라 화면 상의 미로에서 에이전트를 이동시키는 애니메이션을 구현한다.\n",
    "'''\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def init():\n",
    "    \n",
    "    # 배경 이미지 초기화\n",
    "    line.set_data([], [])\n",
    "    \n",
    "    return (line,)\n",
    "\n",
    "def animate(i):\n",
    "    \n",
    "    # 프레임 단위 이미지 생성\n",
    "    \n",
    "    # 현재 위치\n",
    "    state = state_history[i]\n",
    "    \n",
    "    # 상태 s의 x좌표(3으로 나눈 나머지 + 0.5)\n",
    "    x = (state % 3) + 0.5\n",
    "    \n",
    "    # 상태 s의 y좌표(2.5에서 3으로 나눈 몫을 뺌)\n",
    "    y = 2.5 - int(state / 3)\n",
    "    \n",
    "    line.set_data(x, y)\n",
    "    \n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "init() 함수와 animate() 함수를 사용하여 애니메이션 생성\n",
    "'''\n",
    "anim = animation.FuncAnimation(\n",
    "    fig,\n",
    "    animate, \n",
    "    init_func = init,\n",
    "    frames = len(state_action_history),\n",
    "    interval = 200,\n",
    "    repeat = False\n",
    ")\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
